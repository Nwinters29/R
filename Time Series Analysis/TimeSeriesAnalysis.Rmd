---
title: "Time Series Analysis"
author: "Nick Winters"
date: "7/9/24"
output:
    html_document:
     toc: true
     toc_float: true
---

# I. Overview

## Specific Task

This project aims to utilize various types of regression to forecast future values in a time series analysis. The data and the general workflow of the code was provided by the Eastern University course "Data Science for Business". 

# II. Setup

## Load Packages

The first step involved loading the necessary libraries for this analysis.

```{r}
#load libraries
library(tidyverse)
library(TTR)
```

## Set working directory

Next the working directory was set in order to retrieve the data files.

```{r}
#set working directory
setwd("/Users/nickwinters/desktop/DS Projects/R/TimeSeriesAnalysis")
```

## Metrics for Evaluations

Since regression was used for this analysis, the metrics used to evaluate each regression model was created via functions. These metrics relay how accurate each model is at predicting the outcome variable by indicating the error between the predicted and actual measures. Each metric relays this information in a different manner. 

  - **mae:** the average `absolute` difference in observed vs predicted
  - **mse:** the average `squared` difference in observed vs predicted
  - **rmse:** the `squareroot` of mse
  - **mape:** the average absolute `percent` difference in observed vs predicted
  
These metrics are relative values so they are beneficial at comparing between two different models.

```{r}
# mean absolute error
mae<-function(actual,pred){
  mae <- mean(abs(actual-pred), na.rm=TRUE)
  return (mae)
}

# mean squared error
mse<-function(actual,pred){
  mse <- mean((actual-pred)^2, na.rm=TRUE)
  return (mse)
}

# root mean squared error
rmse<-function(actual,pred){
  rmse <- sqrt(mean((actual-pred)^2, na.rm=TRUE))
  return (rmse)
}  

# mean absolute percentage error
mape<-function(actual,pred){
  mape <- mean(abs((actual - pred)/actual), na.rm=TRUE)*100
  return (mape)
}
```

# III. Forecasting with Regression {.tabset}

Regression is a statistical technique that allows for the prediction of an outcome variable based on an input variable/s. This is achieved through the creation of a line of best fit. This line's formula (y = mx + b) can be used to calculate or forecast the outcome variable.

Below are four business scenarios that utilize regression to forecast desired outcome variables.

The general structure of conducting these analysis include the following:

  - Reading in the data from a csv file 
  - Plotting a time series plot
  - Manipulating data where needed
  - Building the regression model
  - Producing accuracy metrics
  - generating predictions based on the model

## Strabucks Yearly Revenue 

### Load & Peak the Data

```{r}
#read dataset into R
starbucksdf <- read.csv("starbucks_revenue.csv")
starbucksdf
```
**Observation:** This data frame holds 19 years of yearly revenue (in billions) for Starbucks.

### Time Series Plot

```{r}
#create a time series plot showing yearly net revenue in billions
ggplot(data = starbucksdf, mapping = aes(x = Year, y = NetRevenue)) +
  geom_line () +
  geom_point() +
  labs(title = "Starbucks Yearly Net Revenue in Billions of Dollars, 
       2003 to 2021", x = "Year", y = "Net Revenue")
```

**Observation:** This time series plot shows an overall positive trend in yearly revenue. There is a notable dip in the 2020 revenue. This is likely due to the COVID-19 epidemic due worldwide lockdowns. This dip does show some recovery in the following 2021 year. 

### Data Manipulation

To help simplify the model, instead of using the year as the predictor variable (due to its datatype being an integer) a new column was created that expresses each year as representative number. 

```{r}
# Add column of values representing the true revenue
starbucksdf$TrueRevenue <- (starbucksdf$NetRevenue) * 10^9
# Add a column of consecutive numbers
starbucksdf$Time <- 1:nrow(starbucksdf)
# view changes
head(starbucksdf)
```

### Create a Linear Regression Model

Since there is only one outcome variable (`NetRevenue`), linear regression is the model that was used for this scenario. 
```{r}
# simple linear regression analysis
sb_reg<-lm(NetRevenue ~ Time, data = starbucksdf)
summary(sb_reg)
```

**Observation:** The line of best fit is equal to $y = 1.209x + 2.547$. This indicates that the year over year growth in revenue is 1.2 billion dollars.

### Accuracy Metrics
```{r}
# Predicted values were generated for evaluation
sb_pred = predict(sb_reg)

# Run previously created metric functions
mae (starbucksdf$NetRevenue, sb_pred)
mse (starbucksdf$NetRevenue, sb_pred)
rmse (starbucksdf$NetRevenue, sb_pred)
mape (starbucksdf$NetRevenue, sb_pred)
```
**Note:** These values generated above depict the models accuracy; however because they are relative values, they are really only beneficial at comparing between diffent models. 

### Generate Predictions

For this specific scenario, the net revenue for the years 2022, 2023, and 2024 were predicted
```{r}
# Create a data frame with the time periods to use for the prediction
sb_new <- data.frame(Time = c(20, 21, 22))
predict(sb_reg, newdata = sb_new)
```

### Residual vs Predicted Plot
```{r}
#Create a vector of residuals generated from the regression above
sb_res = resid(sb_reg)

#Create a data frame of the predicted values and the residuals
pred_res_df <- data.frame(sb_pred, sb_res)

#create a scatterplot of the residuals versus the predicted values
ggplot(data = pred_res_df, mapping = aes(x = sb_pred, y = sb_res)) +
  geom_point() +
  labs(title = "Plot of residuals vs. predicted values", x = "Predicted values",
       y = "Residuals")
```

**Observation:** In an ideal scenario, the points on this plot should be randomly scattered around the zero line; however here we see a case of autocorrelation. In this case this means that data from the current year may be correlated with data from the previous year. This depicted by the apparent upward trend that points are following. If future analysis is conducted on this data it may be beneficial to create an autoregression model to account for this observation. 


## New York Times Quarterly Revenue

### Load & Peak the Data

```{r}
#read dataset into R
nytdf <- read.csv("NYT_revenue.csv")
nytdf
```

**Observation:** This data frame holds 3 years of revenue divided up by quarter for New York Times Magazine.

### Time Series Plot

```{r}
#create a time series plot showing NYT quarterly revenue
ggplot(data = nytdf, mapping = aes(x = Quarter, y = Revenue)) +
  geom_line (group=1) +
  geom_point() +
  labs(title = "New York Times Quarterly Revenue 2013 to 2016", 
       x = "Quarter", y = "Revenue")
```

**Observation:** This time series plot shows an a seasonal horizontal trend, with spikes in revenue every 4th quarter. 

### Data Manipulation

To implement regression in this scenario, first binary variables were created to represent each quarter.
```{r}
# add column to represent the true revenue value
nytdf$TrueRevenue <- nytdf$Revenue * 10^6
# dummy variables corresponding to each quarter were created
nytdf$Q1 <- ifelse(grepl("Q1",nytdf$Quarter), 1, 0)
nytdf$Q2 <- ifelse(grepl("Q2",nytdf$Quarter), 1, 0)
nytdf$Q3 <- ifelse(grepl("Q3",nytdf$Quarter), 1, 0)
nytdf$Q4 <- ifelse(grepl("Q4",nytdf$Quarter), 1, 0)
# check newly manipulated variable
head(nytdf)
```

### Create a Multiple Regression Model

Multiple regression was used since there are multiple outcome variables. For this regression `Q4` was intnetionaly left out to be the reference variable.
```{r}
#Use multiple regression with quarter variables to generate a regression 
#equation for forecasting
nyt_reg<-lm(Revenue ~ Q1 + Q2 + Q3, data = nytdf)
summary(nyt_reg)
```
**Observation:** The line of best fit is equal to $y = -59.5x -59.4x -78.9x + 443.2$. This indicates that the year over year growth in revenue is 1.2 billion dollars. These coefficients indicate how much less each quarters revenue is in relation to Q4.

### Accuracy Metrics

```{r}
#Create a vector of predicted values
nyt_pred = predict(nyt_reg)

# calculate accuracy measures
mae(nytdf$Revenue, nyt_pred)
mse(nytdf$Revenue, nyt_pred)
rmse(nytdf$Revenue, nyt_pred)
mape(nytdf$Revenue, nyt_pred)
```
**Note:** These values generated above depict the models accuracy; however because they are relative values, they are really only beneficial at comparing between diffent models. 

### Generate Predictions

For this specific scenario, the revenue for Q1, Q2, Q3, Q4 of 2017 were predicted.
```{r}
# Create an object with the time periods to use for the prediction
nyt_new <- data.frame(Q1 = c(1,0,0,0), Q2 = c(0,1,0,0), Q3 = c(0,0,1,0)) 
predict(nyt_reg, newdata = nyt_new)
```

## Whole Foods Quarterly Revenue

### Load & Peak the Data

```{r}
#read dataset into R
wfdf <- read.csv("whole_foods.csv")
wfdf
```
**Observation:** This data frame holds 11 years of revenue divided up by quarter for Whole Foods.

### Time Series Plot

```{r}
#create a time series plot showing quarterly net sales
ggplot(data = wfdf, mapping = aes(x = Quarter, y = Net.Sales)) +
  geom_line (group=1) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90)) + 
  labs(title = "Whole Foods Quarterly Net Sales 2005 to 2016 in $ millions", 
       x = "Quarter", y = "Net Sales")
```

**Observation:** This time series plot shows an a seasonal upward trend, with spikes in revenue every 1st quarter. 

### Data Manipulation

To implement regression in this scenario, first a new column was added to represent each year and the binary variables were created to represent each quarter.
```{r}
# add column of values representing the true sales value
wfdf$True.Sales <- wfdf$Net.Sales * 10^6

# add column of consecutive numbers for each year
wfdf$Time <- 1:nrow(wfdf) 

# create dummy variables corresponding to each quarter 
wfdf$Q1 <- ifelse(grepl("Q1",wfdf$Quarter), 1, 0)
wfdf$Q2 <- ifelse(grepl("Q2",wfdf$Quarter), 1, 0)
wfdf$Q3 <- ifelse(grepl("Q3",wfdf$Quarter), 1, 0)
wfdf$Q4 <- ifelse(grepl("Q4",wfdf$Quarter), 1, 0)

# veiw manipulated df
head(wfdf)
```

### Linear Regression Model 

A linear regression model was created to predict `NetSales` from `Time`.
```{r}
# linear regression model
wf_reg<-lm(Net.Sales ~ Time, data = wfdf)
summary(wf_reg)
```

**Observation:** The line of best fit is equal to $y = 0.06x + 0.980$. This indicates that the year over year growth in revenue is 0.06 billion dollars.

### Accuracy Metrics
```{r}
# create a vector of predicted values
wf_pred = predict(wf_reg)

# calculate accuracy measures
mae(wfdf$Net.Sales, wf_pred)
mse(wfdf$Net.Sales, wf_pred)
rmse(wfdf$Net.Sales, wf_pred)
mape(wfdf$Net.Sales, wf_pred)
```

### Multiple Regression Model

To also account for the seasonality trend depicted in the time series plot as well as the upward trend seen year to year, a multiple regression model was created where `Net.Sales` is the outcome variable, and `Time`, `Q2`, `Q3`, and `Q4` were the predictor variables. `Q1` was chosen as the reference varible. 

```{r}
# multiple regression with the time and quarters
wf_mreg<-lm(Net.Sales ~ Time + Q2 + Q3 + Q4, data = wfdf)
summary(wf_mreg)
```
**Observation:** The line of best fit is equal to $y = 0.06x - 0.74x - 0.77x - 0.88x + 1.53$. This indicates that the year over year growth in revenue is 0.065 billion dollars, and the Q2-Q4 coefficients represent the change in sales relative to Q1.

### Accuracy Metrics
```{r}
# create a vector of predicted values
wf_pred2 = predict(wf_mreg)

# calculate accuracy measures
mae(wfdf$Net.Sales, wf_pred2)
mse(wfdf$Net.Sales, wf_pred2)
rmse(wfdf$Net.Sales, wf_pred2)
mape(wfdf$Net.Sales, wf_pred2)
```
**Observation:** Comparing metrics between both the `wf_reg` and `wf_mreg` model indicates that the latter is the better fit due to its error being comparatively lower than when just linear regression was employed.

### Generate Predictions

For this specific scenario, the Whole Foods net sales for 2017 Q1, Q2, Q3, and Q4 were predicted using the multiple regression model. 
```{r}
# create an object with the time periods to use for the prediction
new <- data.frame(Time = c(49, 50, 51, 52), Q2 = c(0,1,0,0), Q3 = c(0,0,1,0), 
                  Q4 = c(0,0,0,1)) 
predict(wf_mreg, newdata = new)
```

## LinkedIn Quarterly Members

### Load & Peak the Data

```{r}
#read dataset into R
lidf <- read.csv("linked_in.csv")
lidf
```

**Observation:** This data frame holds 5 years of memberships divided up by quarter for LinkedIn.

### Time Series Plot

```{r}
#create a time series plot showing number of LinkedIn members by quarter, 
#in millions
ggplot(data = lidf, mapping = aes(x = Quarter, y = Members)) +
  geom_line (group=1) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(title = "LinkedIn members by Quarter (millions), 2009 to 2014", 
       x = "Quarter", y = "Members")
```

**Observation:** This time series plot shows an upward sloping trend in memberships.

### Data Manipulation

To implement regression in this scenario, first a new column (`Time`) of consecutive numbers was added to represent each quarter and a new variable was created by squaring the `Time` variable.
```{r}
# add column of consecutive numbers corresponding with each quarter
lidf$Time <- 1:nrow(lidf) 

# create a new variable that squares the Time variable
lidf$Time2 <- lidf$Time^2

# check data
lidf
```

### Linear Regression Model

The first model created was a simple linear regression model, where `Members` was the outcome and `Time` was used as the predictor.
```{r}
# simple linear regression
li_reg<-lm(Members ~ Time, data = lidf)
summary(li_reg)
```
**Observation:** The line of best fit is equal to $y = 13.4x - 3.7$. This indicates that the quarter to quarter growth in membership is a gain of 13 million members.


### Accuracy Metrics
```{r}
# create a vector of predicted values
li_pred = predict(li_reg)

# calculate accuracy measures 
mae (lidf$Members, li_pred)
mse (lidf$Members, li_pred)
rmse (lidf$Members, li_pred)
mape (lidf$Members, li_pred)
```

### Quadratic Regression

Next, because there was indication of an exponential trend in the time series plot, a quadratic or polynomial model was created by adding `Time2` as a predictor.
```{r}
# quadratic regression model
li_qreg<-lm(Members ~ Time + Time2, data = lidf)
summary(li_qreg)
```
**Observation:** The line of best fit is equal to $y = 0.36x^2 + 5.08x + 29.57$.

### Accuracy Metrics
```{r}
# create a vector of predicted values
li_pred2 = predict(li_qreg)

# calculate accuracy measures
mae (lidf$Members, li_pred2)
mse (lidf$Members, li_pred2)
rmse (lidf$Members, li_pred2)
mape (lidf$Members, li_pred2)
```
**Observation:** Comparing metrics between both the `li_reg` and `li_qreg` model indicates that the latter is the better fit due to its error being significantly lower than when just linear regression was employed.

### Generate Predictions

For this specific scenario, LinkedIn memberships for Q3 and Q4 of 2014 were predicted using the quadratic regression model. 
```{r}
# Create an object with the time periods to use for the prediction
li_new <- data.frame(Time = c(23, 24), Time2 = c(529, 576))
predict(li_qreg, newdata = li_new)
```

# IV. Conclusion

This time series analysis successfully forecasted various outcome variables by utilizing various methods of regression. The techniques used in this project could just as easily be adapted to other business scenarios depending on the trends depicted in a time series plot.